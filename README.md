<<<<<<< HEAD
# PingPang_Detection_Car
æˆ‘å›½ç°åœ¨å€¡å¯¼å…¨æ°‘ä½“è‚²ï¼Œå…¨æ°‘å¥èº«ï¼Œæ™ºèƒ½åŒ–ä½“è‚²ã€‚ä¹’ä¹“çƒè™½ç„¶åªæ˜¯æ¯”èµ›å½“ä¸­çš„ä¸€ä¸ªå°çƒï¼Œä½†å´æ˜¯æˆ‘ä»¬ä¸­å›½çš„å›½çƒã€‚é™¤äº†ä¸“ä¸šçš„ä¹’ä¹“çƒè¿åŠ¨å‘˜ï¼Œä¸šä½™çˆ±å¥½è€…ä¹Ÿæ˜¯å¸¸å¸¸ä¼šåœ¨ç©ºé—²åœ°æ—¶é—´ä¸äºŒä¸‰ä¸ªå¿—åŒé“åˆçš„çƒå‹å»å…µä¹“çƒé¦†å†…è¿›è¡Œå¯¹ç»ƒã€‚åªæ˜¯æ¯æ¬¡é•¿æ—¶é—´çš„è®­ç»ƒç»“æŸåï¼Œåœ°æ¿ä¸Šéƒ½èƒ½çœ‹åˆ°å››å¤„æ•£è½çš„å…µä¹“çƒï¼Œç»™åœºåœ°å·¥ä½œäººå‘˜å¸¦æ¥å›°æ‰°ã€‚å› æ­¤ï¼Œå°±éœ€è¦å¯è‡ªåŠ¨æ‹¾å–ä¹’ä¹“çƒçš„æœºå™¨äººæ¥èŠ‚çœä¸€äº›ä¸å¿…è¦çš„äººåŠ›ï¼Œæ»¡è¶³äººä»¬çš„éœ€æ±‚ã€‚åŒæ—¶ï¼Œå¦‚æœèƒ½æœ‰ä¸€ç§æ¡çƒæœºå™¨äººåº”ç”¨äºä¹’ä¹“çƒèµ›åœºä¸Šï¼Œä¸”èƒ½è¿…é€Ÿæ‰¾åˆ°çƒçš„ä½ç½®å¹¶èƒ½å¤Ÿå®ç°è‡ªåŠ¨æ¡çƒçš„åŠŸèƒ½ï¼Œå°†å¯ä»¥å¸®åŠ©é€‰æ‰‹èŠ‚çœçŸ­æš‚çš„ä¼‘æ¯æ—¶é—´ï¼Œä¿è¯æ¯”èµ›çš„è¿ç»­æ€§ä¸æµç•…æ€§ã€‚æ‰€ä»¥ï¼Œä¸“é—¨é’ˆå¯¹ä¹’ä¹“çƒè¿›è¡Œè‡ªåŠ¨æ‹¾å–çš„æ¡çƒæœºå™¨äººä¾¿ç”±æ­¤åº”è¿è€Œç”Ÿã€‚
=======
### é¡¹ç›®åŸåœ°å€ï¼šã€AIè¾¾äººåˆ›é€ è¥ç¬¬ä¸‰æœŸã€‘ä¹’ä¹“çƒæ‹¾æ¡å°è½¦ï¼šhttps://aistudio.baidu.com/aistudio/projectdetail/4589024?sUid=2131908&shared=1&ts=1672822329812

# ä¸€ã€é¡¹ç›®èƒŒæ™¯

æˆ‘å›½ç°åœ¨å€¡å¯¼å…¨æ°‘ä½“è‚²ï¼Œå…¨æ°‘å¥èº«ï¼Œæ™ºèƒ½åŒ–ä½“è‚²ã€‚ä¹’ä¹“çƒè™½ç„¶åªæ˜¯æ¯”èµ›å½“ä¸­çš„ä¸€ä¸ªå°çƒï¼Œä½†å´æ˜¯æˆ‘ä»¬ä¸­å›½çš„å›½çƒã€‚é™¤äº†ä¸“ä¸šçš„ä¹’ä¹“çƒè¿åŠ¨å‘˜ï¼Œä¸šä½™çˆ±å¥½è€…ä¹Ÿæ˜¯å¸¸å¸¸ä¼šåœ¨ç©ºé—²åœ°æ—¶é—´ä¸äºŒä¸‰ä¸ªå¿—åŒé“åˆçš„çƒå‹å»å…µä¹“çƒé¦†å†…è¿›è¡Œå¯¹ç»ƒã€‚åªæ˜¯æ¯æ¬¡é•¿æ—¶é—´çš„è®­ç»ƒç»“æŸåï¼Œåœ°æ¿ä¸Šéƒ½èƒ½çœ‹åˆ°å››å¤„æ•£è½çš„å…µä¹“çƒï¼Œç»™åœºåœ°å·¥ä½œäººå‘˜å¸¦æ¥å›°æ‰°ã€‚å› æ­¤ï¼Œå°±éœ€è¦å¯è‡ªåŠ¨æ‹¾å–ä¹’ä¹“çƒçš„æœºå™¨äººæ¥èŠ‚çœä¸€äº›ä¸å¿…è¦çš„äººåŠ›ï¼Œæ»¡è¶³äººä»¬çš„éœ€æ±‚ã€‚åŒæ—¶ï¼Œå¦‚æœèƒ½æœ‰ä¸€ç§æ¡çƒæœºå™¨äººåº”ç”¨äºä¹’ä¹“çƒèµ›åœºä¸Šï¼Œä¸”èƒ½è¿…é€Ÿæ‰¾åˆ°çƒçš„ä½ç½®å¹¶èƒ½å¤Ÿå®ç°è‡ªåŠ¨æ¡çƒçš„åŠŸèƒ½ï¼Œå°†å¯ä»¥å¸®åŠ©é€‰æ‰‹èŠ‚çœçŸ­æš‚çš„ä¼‘æ¯æ—¶é—´ï¼Œä¿è¯æ¯”èµ›çš„è¿ç»­æ€§ä¸æµç•…æ€§ã€‚æ‰€ä»¥ï¼Œä¸“é—¨é’ˆå¯¹ä¹’ä¹“çƒè¿›è¡Œè‡ªåŠ¨æ‹¾å–çš„æ¡çƒæœºå™¨äººä¾¿ç”±æ­¤åº”è¿è€Œç”Ÿã€‚

# äºŒã€æ¨¡å‹å‡†å¤‡

## ï¼ˆä¸€ï¼‰ã€æ•°æ®é›†å¤„ç†

### 1.è§£å‹æ•°æ®é›†


```python
# è§£å‹ç¼©æ•°æ®åˆ°æŒ‡å®šç›®å½•
! tar -xf /home/aistudio/data/data136961/tabletennis_voc.tar -C ~/work/
```

### 2.æŒ‰æ¯”ä¾‹åˆ’åˆ†æ•°æ®é›†


```python
%cd /home/aistudio
import random
import os
#ç”Ÿæˆtrain.txtå’Œval.txt
random.seed(2020)
xml_dir  = '/home/aistudio/work/tabletennis_voc/voc/annotations'#æ ‡ç­¾æ–‡ä»¶åœ°å€
img_dir = '/home/aistudio/work/tabletennis_voc/voc/images'#å›¾åƒæ–‡ä»¶åœ°å€
path_list = list()
for img in os.listdir(img_dir):
    img_path = os.path.join(img_dir,img)
    xml_path = os.path.join(xml_dir,img.replace('jpg', 'xml'))
    path_list.append((img_path, xml_path))
random.shuffle(path_list)
ratio = 0.7
train_f = open('/home/aistudio/work/tabletennis_voc/voc/train.txt','w') #ç”Ÿæˆè®­ç»ƒæ–‡ä»¶
val_f = open('/home/aistudio/work/tabletennis_voc/voc/val.txt' ,'w')#ç”ŸæˆéªŒè¯æ–‡ä»¶

for i ,content in enumerate(path_list):
    img, xml = content
    text = img + ' ' + xml + '\n'
    if i < len(path_list) * ratio:
        train_f.write(text)
    else:
        val_f.write(text)
train_f.close()
val_f.close()

#ç”Ÿæˆæ ‡ç­¾æ–‡æ¡£
label = ['ball']#è®¾ç½®ä½ æƒ³æ£€æµ‹çš„ç±»åˆ«
with open('/home/aistudio/work/tabletennis_voc/voc/label_list.txt', 'w') as f:
    for text in label:
        f.write(text+'\n')
```

    /home/aistudio


### 3.æ•°æ®é›†æŸ¥çœ‹
æºæ•°æ®æ ¼å¼ä¸ºVOCæ ¼å¼ï¼Œå­˜å‚¨æ ¼å¼å¦‚ä¸‹ï¼š
![](https://ai-studio-static-online.cdn.bcebos.com/a5e2be8dfa2642639366135d410e72406c24f5dc1f3a4ab7a94a7eea44c7a555)


## ï¼ˆäºŒï¼‰ã€ç¯å¢ƒå‡†å¤‡

### 1.PP-PicoDetä»‹ç»

![](https://ai-studio-static-online.cdn.bcebos.com/c5867cee2383418e918f84f579b8e8a2a4e1752a01f84803b6663df683178fe6)


PaddleDetectionä¸­æå‡ºäº†å…¨æ–°çš„è½»é‡çº§ç³»åˆ—æ¨¡å‹`PP-PicoDet`ï¼Œåœ¨ç§»åŠ¨ç«¯å…·æœ‰å“è¶Šçš„æ€§èƒ½ï¼Œæˆä¸ºå…¨æ–°SOTAè½»é‡çº§æ¨¡å‹ã€‚è¯¦ç»†çš„æŠ€æœ¯ç»†èŠ‚å¯ä»¥å‚è€ƒæˆ‘ä»¬çš„[arXivæŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2111.00902)ã€‚

PP-PicoDetæ¨¡å‹æœ‰å¦‚ä¸‹ç‰¹ç‚¹ï¼š

- ğŸŒŸ æ›´é«˜çš„mAP: ç¬¬ä¸€ä¸ªåœ¨1Må‚æ•°é‡ä¹‹å†…`mAP(0.5:0.95)`è¶…è¶Š**30+**(è¾“å…¥416åƒç´ æ—¶)ã€‚
- ğŸš€ æ›´å¿«çš„é¢„æµ‹é€Ÿåº¦: ç½‘ç»œé¢„æµ‹åœ¨ARM CPUä¸‹å¯è¾¾150FPSã€‚
- ğŸ˜Š éƒ¨ç½²å‹å¥½: æ”¯æŒPaddleLite/MNN/NCNN/OpenVINOç­‰é¢„æµ‹åº“ï¼Œæ”¯æŒè½¬å‡ºONNXï¼Œæä¾›äº†C++/Python/Androidçš„demoã€‚
- ğŸ˜ å…ˆè¿›çš„ç®—æ³•: æˆ‘ä»¬åœ¨ç°æœ‰SOTAç®—æ³•ä¸­è¿›è¡Œäº†åˆ›æ–°, åŒ…æ‹¬ï¼šESNet, CSP-PAN, SimOTAç­‰ç­‰ã€‚ç›®å‰

### 2.æ•°æ®æ ¼å¼
ç›®å‰PP-PicoDetæ”¯æŒ **VOC** å’Œ **COCO** ä¸¤ç§æ ¼å¼ï¼Œå¯æ ¹æ®éœ€è¦é€‰æ‹©ã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/ba2f037c289f454086aa66484cb539736c19535de15f457289b9313e3a59fcd3)

### 3.åŸºçº¿


| æ¨¡å‹     | è¾“å…¥å°ºå¯¸ | mAP<sup>val<br>0.5:0.95 | mAP<sup>val<br>0.5 | å‚æ•°é‡<br><sup>(M) | FLOPS<br><sup>(G) | é¢„æµ‹æ—¶å»¶<sup><small>[NCNN](#latency)</small><sup><br><sup>(ms) | é¢„æµ‹æ—¶å»¶<sup><small>[Lite](#latency)</small><sup><br><sup>(ms) |  ä¸‹è½½  | é…ç½®æ–‡ä»¶ |
| :-------- | :--------: | :---------------------: | :----------------: | :----------------: | :---------------: | :-----------------------------: | :-----------------------------: | :----------------------------------------: | :--------------------------------------- |
| PicoDet-S |  320*320   |          27.1           |        41.4        |        0.99        |       0.73        |              8.13               |            **6.65**             | [model](https://paddledet.bj.bcebos.com/models/picodet_s_320_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_s_320_coco.log) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/picodet_s_320_coco.yml) |
| PicoDet-S |  416*416   |          30.7           |        45.8        |        0.99        |       1.24        |              12.37              |            **9.82**             | [model](https://paddledet.bj.bcebos.com/models/picodet_s_416_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_s_416_coco.log) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/picodet_s_416_coco.yml) |
| PicoDet-M |  320*320   |          30.9           |        45.7        |        2.15        |       1.48        |[              ](http://)11.27              |            **9.61**             | [model](https://paddledet.bj.bcebos.com/models/picodet_m_320_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_m_320_coco.log) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/picodet_m_320_coco.yml) |
| PicoDet-M |  416*416   |          34.8           |        50.5        |        2.15        |       2.50        |              17.39              |            **15.88**            | [model](https://paddledet.bj.bcebos.com/models/picodet_m_416_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_m_416_coco.log) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/picodet_m_416_coco.yml) |
| PicoDet-L |  320*320   |          32.9           |        48.2        |        3.30        |       2.23        |              15.26              |            **13.42**            | [model](https://paddledet.bj.bcebos.com/models/picodet_l_320_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_l_320_coco.log) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/picodet_l_320_coco.yml) |
| PicoDet-L |  416*416   |          36.6           |        52.5        |        3.30        |       3.76        |              23.36              |            **21.85**            | [model](https://paddledet.bj.bcebos.com/models/picodet_l_416_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_l_416_coco.log) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/picodet_l_416_coco.yml) |
| PicoDet-L |  640*640   |          40.9           |        57.6        |        3.30        |       8.91        |              54.11              |            **50.55**            | [model](https://paddledet.bj.bcebos.com/models/picodet_l_640_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_l_640_coco.log) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/picodet_l_640_coco.yml) |

 **æ›´å¤šçš„é…ç½®**

| æ¨¡å‹     | è¾“å…¥å°ºå¯¸ | mAP<sup>val<br>0.5:0.95 | mAP<sup>val<br>0.5 | å‚æ•°é‡<br><sup>(M) | FLOPS<br><sup>(G) | é¢„æµ‹æ—¶å»¶<sup><small>[NCNN](#latency)</small><sup><br><sup>(ms) | é¢„æµ‹æ—¶å»¶<sup><small>[Lite](#latency)</small><sup><br><sup>(ms) |  ä¸‹è½½  | é…ç½®æ–‡ä»¶ |
| :--------------------------- | :--------: | :---------------------: | :----------------: | :----------------: | :---------------: | :-----------------------------: | :-----------------------------: | :----------------------------------------: | :--------------------------------------- |
| PicoDet-Shufflenetv2 1x      |  416*416   |          30.0           |        44.6        |        1.17        |       1.53        |              15.06              |            **10.63**            |      [model](https://paddledet.bj.bcebos.com/models/picodet_shufflenetv2_1x_416_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_shufflenetv2_1x_416_coco.log)      | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/more_config/picodet_shufflenetv2_1x_416_coco.yml)      |
| PicoDet-MobileNetv3-large 1x |  416*416   |          35.6           |        52.0        |        3.55        |       2.80        |              20.71              |            **17.88**            | [model](https://paddledet.bj.bcebos.com/models/picodet_mobilenetv3_large_1x_416_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_mobilenetv3_large_1x_416_coco.log) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/more_config/picodet_mobilenetv3_large_1x_416_coco.yml) |
| PicoDet-LCNet 1.5x           |  416*416   |          36.3           |        52.2        |        3.10        |       3.85        |              21.29              |            **20.8**             |           [model](https://paddledet.bj.bcebos.com/models/picodet_lcnet_1_5x_416_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_lcnet_1_5x_416_coco.log)           | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/more_config/picodet_lcnet_1_5x_416_coco.yml)           |
| PicoDet-LCNet 1.5x           |  640*640   |          40.6           |        57.4        |        3.10        |       -        |              -              |            -             |           [model](https://paddledet.bj.bcebos.com/models/picodet_lcnet_1_5x_640_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_lcnet_1_5x_640_coco.log)           | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/more_config/picodet_lcnet_1_5x_640_coco.yml)           |
| PicoDet-R18           |  640*640   |          40.7           |        57.2        |        11.10        |       -        |              -              |            -             |           [model](https://paddledet.bj.bcebos.com/models/picodet_r18_640_coco.pdparams) &#124; [log](https://paddledet.bj.bcebos.com/logs/train_picodet_r18_640_coco.log)           | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.3/configs/picodet/more_config/picodet_r18_640_coco.yml)           |

<details open>
<summary><b>æ³¨æ„äº‹é¡¹:</b></summary>

- <a name="latency">æ—¶å»¶æµ‹è¯•ï¼š</a> æˆ‘ä»¬æ‰€æœ‰çš„æ¨¡å‹éƒ½åœ¨`éªé¾™865(4xA77+4xA55)` ä¸Šæµ‹è¯•(4çº¿ç¨‹ï¼ŒFP16é¢„æµ‹)ã€‚ä¸Šé¢è¡¨æ ¼ä¸­æ ‡æœ‰`NCNN`çš„æ˜¯ä½¿ç”¨[NCNN](https://github.com/Tencent/ncnn)åº“æµ‹è¯•ï¼Œæ ‡æœ‰`Lite`çš„æ˜¯ä½¿ç”¨[Paddle Lite](https://github.com/PaddlePaddle/Paddle-Lite)è¿›è¡Œæµ‹è¯•ã€‚ æµ‹è¯•çš„benchmarkè„šæœ¬æ¥è‡ª: [MobileDetBenchmark](https://github.com/JiweiMaster/MobileDetBenchmark)ã€‚
- PicoDetåœ¨COCO train2017ä¸Šè®­ç»ƒï¼Œå¹¶ä¸”åœ¨COCO val2017ä¸Šè¿›è¡ŒéªŒè¯ã€‚
- PicoDetä½¿ç”¨4å¡GPUè®­ç»ƒ(PicoDet-L-640ä½¿ç”¨8å¡è®­ç»ƒ)ï¼Œå¹¶ä¸”æ‰€æœ‰çš„æ¨¡å‹éƒ½æ˜¯é€šè¿‡å‘å¸ƒçš„é»˜è®¤é…ç½®è®­ç»ƒå¾—åˆ°ã€‚

</details>

  **å…¶ä»–æ¨¡å‹çš„åŸºçº¿**

| æ¨¡å‹     | è¾“å…¥å°ºå¯¸ | mAP<sup>val<br>0.5:0.95 | mAP<sup>val<br>0.5 | å‚æ•°é‡<br><sup>(M) | FLOPS<br><sup>(G) | é¢„æµ‹æ—¶å»¶<sup><small>[NCNN](#latency)</small><sup><br><sup>(ms) |
| :-------- | :--------: | :---------------------: | :----------------: | :----------------: | :---------------: | :-----------------------------: |
| YOLOv3-Tiny |  416*416   |          16.6           |        33.1      |        8.86        |       5.62        |             25.42               |
| YOLOv4-Tiny |  416*416   |          21.7           |        40.2        |        6.06           |       6.96           |             23.69               |
| PP-YOLO-Tiny |  320*320       |          20.6         |        -              |   1.08             |    0.58             |    6.75                           |  
| PP-YOLO-Tiny |  416*416   |          22.7          |    -               |    1.08               |    1.02             |    10.48                          |  
| Nanodet-M |  320*320      |          20.6            |    -               |    0.95               |    0.72             |    8.71                           |  
| Nanodet-M |  416*416   |          23.5             |    -               |    0.95               |    1.2              |  13.35                          |
| Nanodet-M 1.5x |  416*416   |          26.8        |    -                  | 2.08               |    2.42             |    15.83                          |
| YOLOX-Nano     |  416*416   |          25.8          |    -               |    0.91               |    1.08             |    19.23                          |
| YOLOX-Tiny     |  416*416   |          32.8          |    -               |    5.06               |    6.45             |    32.77                          |
| YOLOv5n |  640*640       |          28.4             |    46.0            |    1.9                |    4.5              |    40.35                          |
| YOLOv5s |  640*640       |          37.2             |    56.0            |    7.2                |    16.5             |    78.05                          |
 

### 4.å®‰è£…

ç¯å¢ƒè¦æ±‚
* PaddlePaddle >= 2.1.2
* Python >= 3.5
* PaddleSlim >= 2.1.1
* PaddleLite >= 2.10**


```python
# å…‹éš†PaddleDetectionä»“åº“
# å¦‚æœå·²ç»å…‹éš†ï¼Œåˆ™ä¸éœ€è¦é‡å¤è¿è¡Œï¼Œå¯æŠŠç¬¬3è¡Œç›´æ¥æ³¨é‡Šï¼Œä»ç¬¬6è¡Œå¼€å§‹è¿è¡Œ
!git clone https://gitee.com/PaddlePaddle/PaddleDetection.git

# å®‰è£…å…¶ä»–ä¾èµ–
%cd PaddleDetection
!pip install -r requirements.txt

# ç¼–è¯‘å®‰è£…paddledet
!python setup.py install
%cd ~
```


```python
# å®‰è£…å…¶ä»–ä¾èµ–
%cd PaddleYOLO
!pip install -r requirements.txt

# ç¼–è¯‘å®‰è£…paddledet
!python setup.py install
%cd ~
```

æœ¬æ¬¡è®­ç»ƒæˆ‘ä»¬é‡‡ç”¨COCOæ•°æ®é›†æ ¼å¼ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å°†æºæ•°æ®é›†è½¬æ¢ä¸ºCOCOæ ¼å¼çš„æ•°æ®é›†ï¼Œå­˜å‚¨æ ¼å¼å¦‚ä¸‹ï¼š![](https://ai-studio-static-online.cdn.bcebos.com/4b11b87b4f114a0591d31c3c9b8724cb70687c17ede64ce6b84159af2f4f46df)



```python
#VOCæ ¼å¼æ•°æ®é›†è½¬æ¢ä¸ºCOCOæ ¼å¼ ä½¿ç”¨Dectionçš„è„šæœ¬è½¬æ¢
#è®­ç»ƒæ–‡ä»¶
%cd ~/PaddleDetection/
! python tools/x2coco.py \
        --dataset_type voc \
        --voc_anno_dir /home/aistudio/work/tabletennis_voc/voc/annotations/ \
        --voc_anno_list /home/aistudio/work/tabletennis_voc/voc/train.txt \
        --voc_label_list /home/aistudio/work/tabletennis_voc/voc/label_list.txt \
        --voc_out_name voc_train.json
```


```python
#æµ‹è¯•æ–‡ä»¶
%cd ~/PaddleDetection/
! python tools/x2coco.py \
        --dataset_type voc \
        --voc_anno_dir /home/aistudio/work/tabletennis_voc/voc/annotations/ \
        --voc_anno_list /home/aistudio/work/tabletennis_voc/voc/train.txt \
        --voc_label_list /home/aistudio/work/tabletennis_voc/voc/label_list.txt \
        --voc_out_name voc_val.json
```


```python
#å°†è½¬æ¢çš„jsonæ–‡ä»¶ç§»åˆ°æŒ‡å®šæ–‡ä»¶å¤¹ æˆ‘ä»¬è¿›è¡Œcocoæ ¼å¼æ•°æ®é›†æ„å»º
! pwd
! mkdir /home/aistudio/work/tabletennis_coco
! mv voc_train.json ~/work/tabletennis_coco/annotations
! mv voc_val.json ~/work/tabletennis_coco/annotations
```


```python
#å¤åˆ¶å›¾ç‰‡è¿‡æ¥
! cp -r /home/aistudio/work/tabletennis_voc/voc/images/* /home/aistudio/work/tabletennis_coco/images/
```

## **ï¼ˆä¸‰ï¼‰ã€æ‰§è¡Œè®­ç»ƒ**

### 1.æ¨¡å‹é€‰æ‹©
å› ä¸ºè¦éƒ¨ç½²åœ¨ç§»åŠ¨ç«¯ï¼Œä¸”ä¿è¯é€Ÿåº¦å¿«å’Œç²¾åº¦é«˜ï¼Œå› æ­¤æˆ‘ä»¬é€‰æ‹©PaddleDetectionæå‡ºçš„å…¨æ–°è½»é‡çº§ç³»åˆ—æ¨¡å‹PP-PicoDetï¼Œæ¨¡å‹æœ‰å¦‚ä¸‹ç‰¹ç‚¹ï¼š

* æ›´é«˜çš„mAP: ç¬¬ä¸€ä¸ªåœ¨1Må‚æ•°é‡ä¹‹å†…mAP(0.5:0.95)è¶…è¶Š30+(è¾“å…¥416åƒç´ æ—¶)ã€‚
* æ›´å¿«çš„é¢„æµ‹é€Ÿåº¦: ç½‘ç»œé¢„æµ‹åœ¨ARM CPUä¸‹å¯è¾¾150FPSã€‚
* éƒ¨ç½²å‹å¥½: æ”¯æŒPaddleLite/MNN/NCNN/OpenVINOç­‰é¢„æµ‹åº“ï¼Œæ”¯æŒè½¬å‡ºONNXï¼Œæä¾›äº†C++/Python/Androidçš„demoã€‚
* å…ˆè¿›çš„ç®—æ³•: æˆ‘ä»¬åœ¨ç°æœ‰SOTAç®—æ³•ä¸­è¿›è¡Œäº†åˆ›æ–°, åŒ…æ‹¬ï¼šESNet, CSP-PAN, SimOTAç­‰ç­‰ã€‚

åœ¨æ­¤é€‰æ‹©PP-PicoDetçš„VOCæ•°æ®é›†è®­ç»ƒé…ç½®

### 2.é…ç½®ä¿®æ”¹
ï¼ˆ1ï¼‰é¦–å…ˆä¿®æ”¹PaddleDetection/configs/datasets/coco_detection.ymlæ–‡ä»¶
å°†é‡Œé¢çš„æ•°æ®é›†é…ç½®æ”¹ä¸ºæœ¬é¡¹ç›®æ‰€éœ€çš„æ•°æ®é›† ä¿®æ”¹å¦‚ä¸‹ï¼š

```
metric: COCO
num_classes: 1

TrainDataset:
  !COCODataSet
    image_dir: images
    anno_path: annotations/voc_train.json
    dataset_dir: /home/aistudio/work/tabletennis_coco
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

EvalDataset:
  !COCODataSet
    image_dir: images
    anno_path: annotations/voc_val.json
    dataset_dir: /home/aistudio/work/tabletennis_coco

TestDataset:
  !ImageFolder
    anno_path: annotations/voc_val.json # also support txt (like VOC's label_list.txt)
    dataset_dir: /home/aistudio/work/tabletennis_coco # if set, anno_path will be 'dataset_dir/anno_path'

```
æ•°æ®é›†åŒ…å«çš„ç±»åˆ«æ•°ï¼šnum_classes 1 (åªè¯†åˆ«ä¹’ä¹“çƒ)

åŒ…å«è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å›¾ç‰‡è·¯å¾„image_dirã€æ ‡æ³¨jsonæ–‡ä»¶è·¯å¾„anno_pathã€æ•°æ®é›†è·¯å¾„dataset_dir 
è·¯å¾„æ”¹ä¸ºï¼šæ„å»ºçš„ä¹’ä¹“çƒcocoæ•°æ®é›†è·¯å¾„

ï¼ˆ2ï¼‰ç„¶åä¿®æ”¹ PaddleDetection/configs/picodet/picodet_m_320_coco_lcnet.yml
ä¿®æ”¹ä»¥ä¸‹å‚æ•°(æˆ–è€…ä¸å˜ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°)

é¢„è®­ç»ƒæ¨¡å‹ï¼špretrain_weights

è®­ç»ƒè¶…å‚æ•°ï¼šepochã€batch_sizeã€base_lr

[è¯¦ç»†é…ç½®æ–‡ä»¶æ”¹åŠ¨å’Œè¯´æ˜](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.3/docs/tutorials/GETTING_STARTED_cn.md#3-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%94%B9%E5%8A%A8%E5%92%8C%E8%AF%B4%E6%98%8E)ã€‚

### 3.æ¨¡å‹è®­ç»ƒ
PaddleDetectionæä¾›äº†å•å¡/å¤šå¡è®­ç»ƒæ¨¡å‹ï¼Œæ»¡è¶³ç”¨æˆ·å¤šç§è®­ç»ƒéœ€æ±‚ï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ï¼š


```python
-r output/yolov3_mobilenet_v1_ssld_270e_coco/169#æ¢å¤è®­ç»ƒ
```


```python
PaddleYOLO/configs/yolov5/yolov5_s_300e_coco.yml
```


```python
# å•å¡GPUä¸Šè®­ç»ƒ
%cd ~
%cd PaddleYOLO
!export CUDA_VISIBLE_DEVICES=0 #windowså’ŒMacä¸‹ä¸éœ€è¦æ‰§è¡Œè¯¥å‘½ä»¤
!python tools/train.py -c configs/yolov5/yolov5_s_300e_coco.yml --eval

# å¤šå¡GPUä¸Šè®­ç»ƒ
# !export CUDA_VISIBLE_DEVICES=0,1,2,3
# !python -m paddle.distributed.launch --gpus 0,1,2,3 tools/train.py \
#             -c configs/picodet/picodet_m_320_coco_lcnet.yml# æ¨¡å‹è®­ç»ƒ
```

## ï¼ˆå››ï¼‰ã€æ¨¡å‹è¯„ä¼°


```python
%cd ~
%cd PaddleYOLO
!python -u tools/eval.py -c  configs/yolov5/yolov5_s_300e_coco.yml  -o weights=output/yolov5_s_300e_coco/best_model.pdparams
```

## ï¼ˆäº”ï¼‰ã€æ¨¡å‹é¢„æµ‹


```python
#æ¨¡å‹é¢„æµ‹
%cd ~
%cd Paddleyolo
# æ›´æ¢"--infer_img"é‡Œçš„å›¾ç‰‡è·¯å¾„ä»¥é¢„æµ‹ä¸åŒçš„å›¾ç‰‡
!python tools/infer.py -c configs/yolov5/yolov5_s_300e_coco.yml \
                    --infer_img=/home/aistudio/work/tabletennis_coco/images/29e49881a1b7c05446801a999af99a13.jpg \
                    --output_dir=infer_output/ \
                    --draw_threshold=0.5 \
                    -o weights=/home/aistudio/PaddleDetection/output/yolov5_s_300e_coco/best_model.pdparams \
                    --use_vdl=Ture
```

### ç»“æœå±•ç¤º

 ![](https://ai-studio-static-online.cdn.bcebos.com/545fb173291a42eb9339bc1d80309d65a4884b4c5b6c4c46b955c12118917406)
 

### å¯¼å‡ºæ¨¡å‹

éœ€è¦å°†æ¨¡å‹è¿›è¡Œå¯¼æˆéƒ¨ç½²éœ€è¦çš„æ¨¡å‹æ ¼å¼ï¼Œæ‰§è¡Œä¸‹é¢å‘½ä»¤ï¼š


```python
!export CUDA_VISIBLE_DEVICES=0
%cd ~/PaddleYOLO/
!python tools/export_model.py \
      -c configs/yolov5/yolov5_s_300e_coco.yml \
      -o weights=output/yolov5_s_300e_coco/best_model.pdparams \
      --output_dir=inference_model
```


```python
!tree ./inference_model/yolov5_s_300e_coco
```

    ./inference_model/yolov3_mobilenet_v1_ssld_270e_coco
    â”œâ”€â”€ infer_cfg.yml
    â”œâ”€â”€ model.pdiparams
    â”œâ”€â”€ model.pdiparams.info
    â””â”€â”€ model.pdmodel
    
    0 directories, 4 files


é¢„æµ‹æ¨¡å‹ä¼šå¯¼å‡ºåˆ°inference_model/ç›®å½•ä¸‹ï¼ŒåŒ…æ‹¬**model.pdmodelã€model.pdiparamsã€model.pdiparams.infoå’Œinfer_cfg.yml**å››ä¸ªæ–‡ä»¶ï¼Œåˆ†åˆ«è¡¨ç¤ºæ¨¡å‹çš„**ç½‘ç»œç»“æ„ã€æ¨¡å‹æƒé‡ã€æ¨¡å‹æƒé‡åç§°å’Œæ¨¡å‹çš„é…ç½®æ–‡ä»¶**ï¼ˆåŒ…æ‹¬æ•°æ®é¢„å¤„ç†å‚æ•°ç­‰ï¼‰çš„æµç¨‹é…ç½®æ–‡ä»¶ã€‚

### é™æ€å›¾é¢„æµ‹
åœ¨ç»ˆç«¯è¾“å…¥ä»¥ä¸‹å‘½ä»¤è¿›è¡Œé¢„æµ‹ï¼Œè¯¦ç»†æ•™ç¨‹è¯·å‚è€ƒPythonç«¯é¢„æµ‹éƒ¨ç½²ï¼š


```python
!export CUDA_VISIBLE_DEVICES=0
'''
    --model_dir: ä¸Šè¿°å¯¼å‡ºçš„æ¨¡å‹è·¯å¾„
    --image_fileï¼šéœ€è¦æµ‹è¯•çš„å›¾ç‰‡
    --image_dirï¼šä¹Ÿå¯ä»¥æŒ‡å®šè¦æµ‹è¯•çš„æ–‡ä»¶å¤¹è·¯å¾„
    --deviceï¼šè¿è¡Œæ—¶çš„è®¾å¤‡ï¼Œå¯é€‰æ‹©CPU/GPU/XPUï¼Œé»˜è®¤ä¸ºCPU
    --output_dirï¼šå¯è§†åŒ–ç»“æœä¿å­˜çš„æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸ºoutput/
'''
!python deploy/python/infer.py \
        --model_dir=./inference_model/yolov5_s_300e_coco \
        --image_file=/home/aistudio/work/tabletennis_coco/images/086aff34ef4859c455ce8c7e2e75a1ba.jpg \
        --device=GPU
```

####  æ³¨é‡Šï¼Œä¸‹é¢ä»£ç ä¸å¿…è¿è¡Œï¼ï¼ï¼ï¼ï¼ï¼ï¼
####  å¯¼å‡ºæ¨¡å‹çš„ç¬¬äºŒç§å†™æ³•ï¼Œå‰é¢å·²ç»å¯¼å‡ºï¼Œä¸å¿…å†æ¬¡è¿è¡Œï¼ï¼ï¼


```python
# æ¨¡å‹å¯¼å‡º
!python -u PaddleDetection/tools/export_model.py -c PaddleYOLO/configs/yolov5/yolov5_s_300e_coco.yml --output_dir=./339 \
                              -o weights=PaddleDetection/output/yolov5_s_300e_coco/219.pdparams

```

æ¨ç†é€Ÿè€—æ—¶ 14.60ms ï¼Œé€Ÿåº¦ç›¸å½“ä¸é”™ã€‚

## (å…­)ã€æ€»ç»“

ä¹’ä¹“çƒæ‹¾å°è½¦çš„æ¨¡å‹è®­ç»ƒéƒ¨åˆ†å°±åˆ°æ­¤ä¸ºæ­¢äº†ï¼ŒPicodetæ¨¡å‹è¿˜æ˜¯å¾ˆä¸é”™çš„ï¼Œæ¨¡å‹æ–‡ä»¶ä¸ä»…å°æ¨ç†é€Ÿåº¦ä¹Ÿå¾ˆä¸é”™ï¼Œåé¢å°†åœ¨Jetson Nanoæ¿å­ä¸Šè¿›è¡Œéƒ¨ç½²ï¼Œå¹¶åˆ¶ä½œå…¶ä»–éƒ¨åˆ†ã€‚

é¸£è°¢å‘¨å›½æºå›¢é˜Ÿæä¾›çš„åŸå§‹æ•°æ®é›†ã€ææˆå®‡å›¢é˜Ÿçš„å¸®åŠ©ï¼ï¼ï¼éå¸¸æ„Ÿè°¢

# ä¸‰ã€Jetson Nanoéƒ¨ç½²

## ï¼ˆ1ï¼‰ç¡¬ä»¶

* 1.Jetson Nanoå¼€å‘æ¿
* 2.æ‰©å±•æ¿ï¼›
* 3.æœé‚¦çº¿è‹¥å¹²ï¼›
* 4.æ˜¾ç¤ºå±ï¼›
* 5.ç½‘çº¿ï¼›
* 6.720Pç½—æŠ€æ‘„åƒå¤´
* ã€‚ã€‚ã€‚

## ï¼ˆ2ï¼‰è½¯ä»¶

* Ubuntu18.04ç³»ç»Ÿï¼›
* Jetson Nanoå®˜æ–¹å¼€å‘å¥—ä»¶åŒ…ï¼ˆ4.6.1ï¼‰ï¼›
* Python3.6ï¼›
* PaddlePaddle2.2.3
* ã€‚ã€‚ã€‚

## ï¼ˆ3ï¼‰Jetson Nanoé…ç½®

### 1.å‚è€ƒèµ„æ–™
http://t.csdn.cn/ewYkA

### 2.USBæ‘„åƒå¤´çš„è°ƒè¯•

é¦–å…ˆï¼Œç›´æ¥å°†æ‘„åƒå¤´çš„USBæ¥å¤´ä¸JetsonNanoè¿æ¥ã€‚
> åœ¨ç»ˆç«¯è¾“å…¥ls /dev/video*ï¼Œå¦‚æœå‡ºç°/dev/video0åˆ™è¯´æ˜æ‘„åƒå¤´è¿æ¥æˆåŠŸã€‚ç”¨ä¸‹é¢è¿™æ®µç¨‹åºæµ‹è¯•ä¸€ä¸‹æ‘„åƒå¤´æ˜¯å¦æ­£å¸¸ï¼ŒUSBæ‘„åƒå¤´åˆå§‹åŒ–æ”¹ä¸ºcap = cv2.VideoCapture(0)ã€‚


```python
import cv2
import numpy as np

def video_demo():
    print("init")
    capture = cv2.VideoCapture(0)#0ä¸ºUSBæ‘„åƒå¤´ï¼Œè¿™é‡Œçš„ç¼–å·æ ¹æ®JetsonNanoè¿”å›ç»“æœå¡«å†™ï¼Œä¸ä¸€å®šä¸º0ï¼Œä¸Šé¢åˆå¦‚ä½•è°ƒå‡ºæ‘„åƒå¤´çš„æ–¹æ³•ã€‚
    while(True):
        ret, frame = capture.read()#æ‘„åƒå¤´è¯»å–,retä¸ºæ˜¯å¦æˆåŠŸæ‰“å¼€æ‘„åƒå¤´,true,falseã€‚ frameä¸ºè§†é¢‘çš„æ¯ä¸€å¸§å›¾åƒ
        frame = cv2.flip(frame, 1)#æ‘„åƒå¤´æ˜¯å’Œäººå¯¹ç«‹çš„ï¼Œå°†å›¾åƒå·¦å³è°ƒæ¢å›æ¥æ­£å¸¸æ˜¾ç¤ºã€‚
        print("OK")
        cv2.imshow("video", frame)
        c = cv2.waitKey(50)
        if c == 27:
            break
    capture.release()

video_demo()
cv2.destroyAllWindows()
```

### 3.å®‰è£…Paddle Inference

é¦–å…ˆæ‹‰å–å®˜æ–¹æœ€æ–°ç‰ˆæœ¬çš„Paddle-Inference-demoå¹¶è§£å‹ï¼š


```python
#æ‹‰å–Paddle-Inference-Demo
!git clone https://github.com/PaddlePaddle/Paddle-Inference-Demo.git
#è§£å‹
!unzip -oq /home/aistudio/Paddle-Inference-Demo-master.zip
```

åœ¨æ‹‰å–Paddle Inferenceçš„è¿‡ç¨‹ä¸­ï¼Œå¯èƒ½å‡ºç°ç½‘ç»œé—®é¢˜æ‹‰å–å¤±è´¥ï¼Œå¯ä»¥å»Giteeï¼ˆç äº‘ï¼‰æ‰¾ä¸€ä¸ªä»“åº“ï¼ŒæŠŠä¸Šè¿°çš„åœ°å€æ¢æ‰å°±è¡Œã€‚

### 4.å®‰è£…PaddlePaddleç¯å¢ƒ

é¦–å…ˆæŸ¥çœ‹Jetpackçš„ç‰ˆæœ¬ï¼š
> cat /etc/nv_tegra_release

ç„¶åæ ¹æ®Jetpackå’ŒPythonçš„ç‰ˆæœ¬åœ¨å®˜ç½‘ä¸Šä¸‹è½½å¯¹åº”çš„PaddlePaddle

![](https://ai-studio-static-online.cdn.bcebos.com/da1329c703034831a0f537f46ca5c5103e2be4a63bcb4bb6ac56fd694a9945ae)

å°†.whlæ–‡ä»¶ä¸‹è½½åé€šè¿‡è¿œç¨‹æ–‡ä»¶ä¼ è¾“è½¯ä»¶winscpä¸Šä¼ åˆ°Jetson nanoä¸­ï¼Œè¿›å…¥.whlæ‰€åœ¨çš„æ–‡ä»¶å¤¹å¹¶è¾“å…¥ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼špip3 install paddlepaddle_gpu-2.1.1-cp36-cp36m-linux_aarch64.whlï¼Œæœ€åæµ‹è¯•ä¸€ä¸‹PaddlePaddleæ˜¯å¦å®‰è£…æˆåŠŸï¼š



```python
# æ‰“å¼€python3æµ‹è¯•
import paddle
paddle.fluid.install_check.run_check()
```

è¾“å‡ºç»“æœå‚è€ƒï¼š
![](https://ai-studio-static-online.cdn.bcebos.com/bdcd4b58d1454925b02e0adb6a38a22881a881a02b6649c9accc2fd5f0828969)


### 5.éƒ¨ç½²æ¨¡å‹

å°†å·²ç»åœ¨AI Studioä¸­å¯¼å‡ºçš„æ¨¡å‹ä¸‹è½½ä¸‹æ¥

>å­˜å‚¨æ¨¡å‹ç»“æ„çš„ inference.pdmodel

>å­˜å‚¨æ¨¡å‹å‚æ•°çš„ inference.pdiparams

![](https://ai-studio-static-online.cdn.bcebos.com/d83f98444a9341799d6ed340536186e641c7f31f7cf44f73977a14e1e0ecff4a)

å°†è¿™ä¸¤ä¸ªæ¨¡å‹æ–‡ä»¶ä¼ å…¥Jetson nanoå³å¯


### 6.é¢„æµ‹è¿è¡Œ

æ–°å»ºä¸€ä¸ª.txtæ–‡ä»¶ï¼Œç”¨æ¥å­˜æ”¾æ ‡ç­¾â€œballâ€ã€‚

#### åœ¨Jetson Nanoä¸Šè¿è¡Œä»¥ä¸‹ä»£ç :

#### 1. å¯¼å…¥èµ„æºåº“


```python
import cv2
import numpy as np
from paddle.inference import Config
from paddle.inference import PrecisionType
from paddle.inference import create_predictor
import yaml
import time
import threading
```

#### 2. å›¾åƒé¢„å¤„ç†


```python
def resize(img, target_size):
    """resize to target size"""
    if not isinstance(img, np.ndarray):
        raise TypeError('image type is not numpy.')
    im_shape = img.shape
    im_size_min = np.min(im_shape[0:2])
    im_size_max = np.max(im_shape[0:2])
    im_scale_x = float(target_size) / float(im_shape[1])
    im_scale_y = float(target_size) / float(im_shape[0])
    img = cv2.resize(img, None, None, fx=im_scale_x, fy=im_scale_y)
    return img

def normalize(img, mean, std):
    img = img / 255.0
    mean = np.array(mean)[np.newaxis, np.newaxis, :]
    std = np.array(std)[np.newaxis, np.newaxis, :]
    img -= mean
    img /= std
    return img

def preprocess(img, img_size):
    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]
    img = resize(img, img_size)
    img = img[:, :, ::-1].astype('float32')  # bgr -> rgb
    img = normalize(img, mean, std)
    img = img.transpose((2, 0, 1))  # hwc -> chw
    return img[np.newaxis, :]
```

#### 3. æ¨¡å‹é…ç½®å’Œé¢„æµ‹


```python
def predict_config(model_file, params_file):
    '''
    å‡½æ•°åŠŸèƒ½ï¼šåˆå§‹åŒ–é¢„æµ‹æ¨¡å‹predictor
    å‡½æ•°è¾“å…¥ï¼šæ¨¡å‹ç»“æ„æ–‡ä»¶ï¼Œæ¨¡å‹å‚æ•°æ–‡ä»¶
    å‡½æ•°è¾“å‡ºï¼šé¢„æµ‹å™¨predictor
    '''
    # æ ¹æ®é¢„æµ‹éƒ¨ç½²çš„å®é™…æƒ…å†µï¼Œè®¾ç½®Config
    config = Config()
    # è¯»å–æ¨¡å‹æ–‡ä»¶
    config.set_prog_file(model_file)
    config.set_params_file(params_file)
    # Configé»˜è®¤æ˜¯ä½¿ç”¨CPUé¢„æµ‹ï¼Œè‹¥è¦ä½¿ç”¨GPUé¢„æµ‹ï¼Œéœ€è¦æ‰‹åŠ¨å¼€å¯ï¼Œè®¾ç½®è¿è¡Œçš„GPUå¡å·å’Œåˆ†é…çš„åˆå§‹æ˜¾å­˜ã€‚
    config.enable_use_gpu(500, 0)
    # å¯ä»¥è®¾ç½®å¼€å¯IRä¼˜åŒ–ã€å¼€å¯å†…å­˜ä¼˜åŒ–ã€‚
    config.switch_ir_optim()
    config.enable_memory_optim()
    config.enable_tensorrt_engine(workspace_size=1 << 30, precision_mode=PrecisionType.Half,max_batch_size=1, min_subgraph_size=5, use_static=False, use_calib_mode=False)
    predictor = create_predictor(config)
    return predictor

def predict(predictor, img):
    
    '''
    å‡½æ•°åŠŸèƒ½ï¼šåˆå§‹åŒ–é¢„æµ‹æ¨¡å‹predictor
    å‡½æ•°è¾“å…¥ï¼šæ¨¡å‹ç»“æ„æ–‡ä»¶ï¼Œæ¨¡å‹å‚æ•°æ–‡ä»¶
    å‡½æ•°è¾“å‡ºï¼šé¢„æµ‹å™¨predictor
    '''
    input_names = predictor.get_input_names()
    for i, name in enumerate(input_names):
        input_tensor = predictor.get_input_handle(name)
        input_tensor.reshape(img[i].shape)
        input_tensor.copy_from_cpu(img[i].copy())
    # æ‰§è¡ŒPredictor
    predictor.run()
    # è·å–è¾“å‡º
    results = []
    # è·å–è¾“å‡º
    output_names = predictor.get_output_names()
    for i, name in enumerate(output_names):
        output_tensor = predictor.get_output_handle(name)
        output_data = output_tensor.copy_to_cpu()
        results.append(output_data)
    return results
```

#### 4. åå¤„ç†


```python
def draw_bbox_image(frame, result, label, threshold=0.5):
    
    for res in result:
        cat_id, score, bbox = res[0], res[1], res[2:]
        if score < threshold:
    	    continue
        for i in bbox:
            int(i)
        xmin, ymin, xmax, ymax = bbox
        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (255,0,255), 2)
        print('category id is {}, bbox is {}'.format(cat_id, bbox))
        try:
            label_id = label[int(cat_id)]
            # #cv2.putText(å›¾åƒ, æ–‡å­—, (x, y), å­—ä½“, å¤§å°, (b, g, r), å®½åº¦)
            cv2.putText(frame, label_id, (int(xmin), int(ymin-2)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)
            cv2.putText(frame, str(round(score,2)), (int(xmin), int(ymin+8)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)
        except KeyError:
            pass

def show_price(frame, result, label, price, threshold=0.5):
    w, h, _ = img.shape
    for res in result:
        cat_id, score, bbox = res[0], res[1], res[2:]
        if score < threshold:
            continue
        label_sum.append(label[int(cat_id)])
        price_sum += int(price[int(cat_id)])
    cv2.putText(frame, "price:"+str(price_sum), (int(w-4), 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
```

#### 5. å®šä¹‰æ‘„åƒå¤´ç±»

åœ¨å®é™…è¿è¡Œè¿‡ç¨‹ä¸­ï¼Œæ‘„åƒå¤´å¸§ç‡è¾ƒé«˜ï¼Œä½†nanoçš„å¤„ç†é€Ÿåº¦è·Ÿä¸ä¸Šï¼Œä¼šå‡ºç°å¡å¸§çš„æƒ…å†µï¼Œè¿™æ—¶å¯ä»¥é€šè¿‡å¤šçº¿ç¨‹çš„æŠ€å·§æ”¹å–„è¿™ä¸€é—®é¢˜ã€‚


```python
class Camera:
    def __init__(self, src=0):
        self.src = src
        self.stream = cv2.VideoCapture(src)
        self.stopped = False
        self.thread =  threading.Thread(target=self.update, args=())
        for _ in range(10): #warm up the camera
            (self.grabbed, self.frame) = self.stream.read()
        
    def start(self):
       self.thread.start()

    def update(self):
        while True:
            if self.stopped:
                return
            (self.grabbed, self.frame) = self.stream.read()

    def read(self):
        return self.grabbed, self.frame

    def stop(self):
        self.stopped = True
    
    def release(self):
        self.stream.release()
```

#### 6. ä¸»å‡½æ•°


```python
# ä».txtæ–‡ä»¶ä¸­è¯»å–label
f = open("./label_list.txt")
label_list = f.read().splitlines()
label = [i.split(":")[0] for i in label_list]
price = [i.split(":")[1] for i in label_list]
print(label)
print(price)
f.close()

# é…ç½®æ¨¡å‹å‚æ•°
model_file = "./model/yolo/model.pdmodel"#è¿™é‡Œæ ¹æ®å…·ä½“çš„æ¨¡å‹æ›´æ”¹å°±è¡Œï¼Œè·¯å¾„å¯ä»¥è‡ªè¡Œè®¾å®šï¼Œä¹Ÿå¯ä»¥å‚è€ƒæˆ‘çš„
params_file = "./model/yolo/model.pdiparams"
# åˆå§‹åŒ–é¢„æµ‹æ¨¡å‹
predictor = predict_config(model_file, params_file)

cap = Camera(0)
cap.start()

# å›¾åƒå°ºå¯¸ç›¸å…³å‚æ•°åˆå§‹åŒ–
ret, img = cap.read()
if ret==False:
    while True:
        print("error")
im_size = 608 
scale_factor = np.array([im_size * 1. / img.shape[0], im_size * 1. / img.shape[1]]).reshape((1, 2)).astype(np.float32)
im_shape = np.array([im_size, im_size]).reshape((1, 2)).astype(np.float32)

while True:
    ret, frame = cap.read()
    # print(frame)
    # é¢„å¤„ç†
    data = preprocess(frame, im_size)

    time_start = time.time()
    # é¢„æµ‹
    result = predict(predictor, [im_shape, data, scale_factor])
    # print(result)
    print('Time Costï¼š{}'.format(time.time()-time_start) , "s")

    draw_bbox_image(frame, result[0], label, threshold=0.5)
    show_price(frame, result[0], label, price, threshold=0.5)

    cv2.imshow("frame", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

print("break")
cap.stop()
cap.release()
cv2.destroyAllWindows()
```

##### åˆ°äº†è¿™é‡Œï¼Œä¹’ä¹“çƒè¯†åˆ«çš„æ¨¡å‹å·²ç»æˆåŠŸè¿è¡Œã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/dd9f461b7cd34e7b885683ae4277085d79226f604fdd4ac8bc94f2a093a0a2a9)


# å››ã€èˆµæœºæ§åˆ¶

## 1.æœºæ¢°è‡‚åŠå››ä¸ªè½®å­æ§åˆ¶


```python
#!/usr/bin/python
# -*- coding: utf-8 -*-

import time
import math
import smbus
import RPi.GPIO as GPIO

Dir = [
    'forward',
    'backward',
]


class serov(object):  # å®šä¹‰ä¸€ä¸ªç±»people
  class Struct(object):
    def __init__(self, max_angle, min_angle, num):
      self.num = num
      self.max_angle = max_angle
      self.min_angle = min_angle

  def make_struct(self, max_angle, min_angle, num):
    return self.Struct(max_angle, min_angle, num)


myserov = serov()
myserov_1 = myserov.make_struct(1000, 2300, 12)
myserov_2 = myserov.make_struct(500, 700, 13)
myserov_3 = myserov.make_struct(2300, 2300, 14)
myserov_4 = myserov.make_struct(800, 1500, 15)

class PCA9685:
    # Registers/etc.
    __SUBADR1 = 0x02
    __SUBADR2 = 0x03
    __SUBADR3 = 0x04
    __MODE1 = 0x00
    __PRESCALE = 0xFE
    __LED0_ON_L = 0x06
    __LED0_ON_H = 0x07
    __LED0_OFF_L = 0x08
    __LED0_OFF_H = 0x09
    __ALLLED_ON_L = 0xFA
    __ALLLED_ON_H = 0xFB
    __ALLLED_OFF_L = 0xFC
    __ALLLED_OFF_H = 0xFD

    def __init__(self, address=0x40, debug=False):
        self.bus = smbus.SMBus(1)
        self.address = address
        self.debug = debug
        if (self.debug):
            print("Reseting PCA9685")
        self.write(self.__MODE1, 0x00)

    def write(self, reg, value):
        "Writes an 8-bit value to the specified register/address"
        self.bus.write_byte_data(self.address, reg, value)
        if (self.debug):
            print("I2C: Write 0x%02X to register 0x%02X" % (value, reg))

    def read(self, reg):
        "Read an unsigned byte from the I2C device"
        result = self.bus.read_byte_data(self.address, reg)
        if (self.debug):
            print("I2C: Device 0x%02X returned 0x%02X from reg 0x%02X" % (self.address, result & 0xFF, reg))
        return result

    def setPWMFreq(self, freq):
        "Sets the PWM frequency"
        prescaleval = 25000000.0  # 25MHz
        prescaleval /= 4096.0  # 12-bit
        prescaleval /= float(freq)
        prescaleval -= 1.0
        if (self.debug):
            print("Setting PWM frequency to %d Hz" % freq)
            print("Estimated pre-scale: %d" % prescaleval)
        prescale = math.floor(prescaleval + 0.5)
        if (self.debug):
            print("Final pre-scale: %d" % prescale)

        oldmode = self.read(self.__MODE1);
        newmode = (oldmode & 0x7F) | 0x10  # sleep
        self.write(self.__MODE1, newmode)  # go to sleep
        self.write(self.__PRESCALE, int(math.floor(prescale)))
        self.write(self.__MODE1, oldmode)
        time.sleep(0.005)
        self.write(self.__MODE1, oldmode | 0x80)

    def setPWM(self, channel, on, off):
        "Sets a single PWM channel"
        self.write(self.__LED0_ON_L + 4 * channel, on & 0xFF)
        self.write(self.__LED0_ON_H + 4 * channel, on >> 8)
        self.write(self.__LED0_OFF_L + 4 * channel, off & 0xFF)
        self.write(self.__LED0_OFF_H + 4 * channel, off >> 8)
        if (self.debug):
            print("channel: %d  LED_ON: %d LED_OFF: %d" % (channel, on, off))

    def setServoPulse(self, channel, pulse):
        "Sets the Servo Pulse,The PWM frequency must be 50HZ"
        pulse = pulse * 4096 / 20000  # PWM frequency is 50HZ,the period is 20000us
        self.setPWM(channel, 0, int(pulse))

    def setDutycycle(self, channel, pulse):
        self.setPWM(channel, 0, int(pulse * (4096 / 100)))

    def setLevel(self, channel, value):
        if (value == 1):
          self.setPWM(channel, 0, 4095)
        else:
          self.setPWM(channel, 0, 0)
  



# æ§åˆ¶æœºå™¨äººåº“
class LOBOROBOT():
    def __init__(self):
        self.PWMA = 0
        self.AIN1 = 2
        self.AIN2 = 1

        self.PWMB = 5
        self.BIN1 = 3
        self.BIN2 = 4

        self.PWMC = 6
        self.CIN2 = 7
        self.CIN1 = 8

        self.PWMD = 11
        self.DIN1 = 25
        self.DIN2 = 24
        self.pwm = PCA9685(0x40, debug=False)
        self.pwm.setPWMFreq(50)
        GPIO.setwarnings(False)
        GPIO.setmode(GPIO.BCM)
        GPIO.setup(self.DIN1,GPIO.OUT)
        GPIO.setup(self.DIN2,GPIO.OUT)

    def MotorRun(self, motor, index, speed):
        if speed > 100:
            return
        if(motor == 0):
            self.pwm.setDutycycle(self.PWMA, speed)
            if(index == Dir[0]):
                self.pwm.setLevel(self.AIN1, 0)
                self.pwm.setLevel(self.AIN2, 1)
            else:
                self.pwm.setLevel(self.AIN1, 1)
                self.pwm.setLevel(self.AIN2, 0)
        elif(motor == 1):
            self.pwm.setDutycycle(self.PWMB, speed)
            if(index == Dir[0]):
                self.pwm.setLevel(self.BIN1, 1)
                self.pwm.setLevel(self.BIN2, 0)
            else:
                self.pwm.setLevel(self.BIN1, 0)
                self.pwm.setLevel(self.BIN2, 1)
        elif(motor == 2):
            self.pwm.setDutycycle(self.PWMC,speed)
            if(index == Dir[0]):
                self.pwm.setLevel(self.CIN1,1)
                self.pwm.setLevel(self.CIN2,0)
            else:
                self.pwm.setLevel(self.CIN1,0)
                self.pwm.setLevel(self.CIN2,1)
        elif(motor == 3):
            self.pwm.setDutycycle(self.PWMD,speed)
            if (index == Dir[0]):
                GPIO.output(self.DIN1,0)
                GPIO.output(self.DIN2,1)
            else:
                GPIO.output(self.DIN1,1)
                GPIO.output(self.DIN2,0)

    def MotorStop(self, motor):
        if (motor == 0):
            self.pwm.setDutycycle(self.PWMA, 0)
        elif(motor == 1):
            self.pwm.setDutycycle(self.PWMB, 0)
        elif(motor == 2):
            self.pwm.setDutycycle(self.PWMC, 0)
        elif(motor == 3):
            self.pwm.setDutycycle(self.PWMD, 0)
    # å‰è¿›
    def t_up(self,speed,t_time):
        self.MotorRun(0,'backward',speed)
        self.MotorRun(1,'forward',speed)
        self.MotorRun(2,'forward',speed)
        self.MotorRun(3,'backward',speed)
        time.sleep(t_time)
    #åé€€
    def t_down(self,speed,t_time):

        self.MotorRun(0,'forward',speed)
        self.MotorRun(1,'backward',speed)
        self.MotorRun(2,'backward',speed)
        self.MotorRun(3,'forward',speed)
        time.sleep(t_time)

    # å·¦ç§»
    def moveLeft(self,speed,t_time):
        self.MotorRun(0,'backward',speed)
        self.MotorRun(1,'forward',speed)
        self.MotorRun(2,'backward',speed)
        self.MotorRun(3,'forward',speed)
        time.sleep(t_time)

    #å³ç§»
    def moveRight(self,speed,t_time):
        
        self.MotorRun(0,'forward',speed)
        self.MotorRun(1,'backward',speed)
        self.MotorRun(2,'forward',speed)
        self.MotorRun(3,'backward',speed)
        time.sleep(t_time)

    # å·¦è½¬
    def turnLeft(self,speed,t_time):
        self.MotorRun(1,'backward',speed)
        self.MotorRun(2,'backward',speed)
        self.MotorRun(3,'backward',speed)
        self.MotorRun(0,'backward',speed)
        time.sleep(t_time)
    
    # å³è½¬
    def turnRight(self,speed,t_time):
        self.MotorRun(0,'forward',speed)
        self.MotorRun(1,'forward',speed)
        self.MotorRun(2,'forward',speed)
        self.MotorRun(3,'forward',speed)
        time.sleep(t_time)
    
    # åœæ­¢
    def t_stop(self,t_time):
        self.MotorStop(0)
        self.MotorStop(1)
        self.MotorStop(2)
        self.MotorStop(3)
        time.sleep(t_time)

        # è¾…åŠ©åŠŸèƒ½ï¼Œä½¿è®¾ç½®èˆµæœºè„‰å†²å®½åº¦æ›´ç®€å•ã€‚

    def magnitude_move_mechanical_arm(self,num, status):

        if num == 1:
            self.move_serov_aim = myserov_1
        elif num == 2:
            self.move_serov_aim = myserov_2
        elif num == 3:
            self.move_serov_aim = myserov_3
        elif num == 4:
            self.move_serov_aim = myserov_4

        if (status == "up"):
            self.end_angle = self.move_serov_aim.min_angle
            self.start_angle = self.move_serov_aim.max_angle
            movestep = 10
        else:
            self.end_angle = self.move_serov_aim.max_angle
            self.start_angle = self.move_serov_aim.min_angle
            movestep = -10
        for i in range(self.start_angle, self.end_angle, movestep):
            self.pwm.setServoPulse(self.move_serov_aim.num, i)
            time.sleep(0.02)

    def move_machine_arm(self):


        self.pwm.setServoPulse(14, 2300)
        self.magnitude_move_mechanical_arm(4, "up")
        self.magnitude_move_mechanical_arm(2, "up")
        self.magnitude_move_mechanical_arm(1, "up")
        self.magnitude_move_mechanical_arm(4, "down")

        self.magnitude_move_mechanical_arm(1, "down")

        self.magnitude_move_mechanical_arm(2, "down")
        self.magnitude_move_mechanical_arm(4, "up")

    # è®¾ç½®èˆµæœºè§’åº¦å‡½æ•°
```

## 2.è°ƒç”¨æ§åˆ¶å°è½¦è¿åŠ¨å’Œä¹’ä¹“çƒè¯†åˆ«æ¨¡å‹çš„å¤„ç†ç¨‹åº

ç”¨äºå°†å°è½¦å’Œæ¨¡å‹è¯†åˆ«çš„ç»“æœå…³è”èµ·æ¥ï¼Œæ§åˆ¶å°è½¦è¿åŠ¨ã€‚


```python
import math

import cv2
import numpy as np
from paddle.inference import Config
from paddle.inference import PrecisionType
from paddle.inference import create_predictor
import yaml
import time
import threading

from LOBOROBOT import LOBOROBOT


def resize(img, target_size):
    """resize to target size"""
    if not isinstance(img, np.ndarray):
        raise TypeError('image type is not numpy.')
    im_shape = img.shape
    im_size_min = np.min(im_shape[0:2])
    im_size_max = np.max(im_shape[0:2])
    im_scale_x = float(target_size) / float(im_shape[1])
    im_scale_y = float(target_size) / float(im_shape[0])
    img = cv2.resize(img, None, None, fx=im_scale_x, fy=im_scale_y)
    return img

def normalize(img, mean, std):
    img = img / 255.0
    mean = np.array(mean)[np.newaxis, np.newaxis, :]
    std = np.array(std)[np.newaxis, np.newaxis, :]
    img -= mean
    img /= std
    return img

def preprocess(img, img_size):
    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]
    img = resize(img, img_size)
    img = img[:, :, ::-1].astype('float32')  # bgr -> rgb
    img = normalize(img, mean, std)
    img = img.transpose((2, 0, 1))  # hwc -> chw
    return img[np.newaxis, :]


def predict_config(model_file, params_file):
    '''
    å‡½æ•°åŠŸèƒ½ï¼šåˆå§‹åŒ–é¢„æµ‹æ¨¡å‹predictor
    å‡½æ•°è¾“å…¥ï¼šæ¨¡å‹ç»“æ„æ–‡ä»¶ï¼Œæ¨¡å‹å‚æ•°æ–‡ä»¶
    å‡½æ•°è¾“å‡ºï¼šé¢„æµ‹å™¨predictor
    '''
    # æ ¹æ®é¢„æµ‹éƒ¨ç½²çš„å®é™…æƒ…å†µï¼Œè®¾ç½®Config
    config = Config()
    # è¯»å–æ¨¡å‹æ–‡ä»¶
    config.set_prog_file(model_file)
    config.set_params_file(params_file)
    # Configé»˜è®¤æ˜¯ä½¿ç”¨CPUé¢„æµ‹ï¼Œè‹¥è¦ä½¿ç”¨GPUé¢„æµ‹ï¼Œéœ€è¦æ‰‹åŠ¨å¼€å¯ï¼Œè®¾ç½®è¿è¡Œçš„GPUå¡å·å’Œåˆ†é…çš„åˆå§‹æ˜¾å­˜ã€‚
    config.enable_use_gpu(500, 0)
    # å¯ä»¥è®¾ç½®å¼€å¯IRä¼˜åŒ–ã€å¼€å¯å†…å­˜ä¼˜åŒ–ã€‚
    config.switch_ir_optim()
    config.enable_memory_optim()
    config.enable_tensorrt_engine(workspace_size=1 << 30, precision_mode=PrecisionType.Half,max_batch_size=1, min_subgraph_size=5, use_static=False, use_calib_mode=False)
    predictor = create_predictor(config)
    return predictor

def predict(predictor, img):
    
    '''
    å‡½æ•°åŠŸèƒ½ï¼šåˆå§‹åŒ–é¢„æµ‹æ¨¡å‹predictor
    å‡½æ•°è¾“å…¥ï¼šæ¨¡å‹ç»“æ„æ–‡ä»¶ï¼Œæ¨¡å‹å‚æ•°æ–‡ä»¶
    å‡½æ•°è¾“å‡ºï¼šé¢„æµ‹å™¨predictor
    '''
    input_names = predictor.get_input_names()
    for i, name in enumerate(input_names):
        input_tensor = predictor.get_input_handle(name)
        input_tensor.reshape(img[i].shape)
        input_tensor.copy_from_cpu(img[i].copy())
    # æ‰§è¡ŒPredictor
    predictor.run()
    # è·å–è¾“å‡º
    results = []
    # è·å–è¾“å‡º
    output_names = predictor.get_output_names()
    for i, name in enumerate(output_names):
        output_tensor = predictor.get_output_handle(name)
        output_data = output_tensor.copy_to_cpu()
        results.append(output_data)
    return results


def draw_bbox_image(frame, result, text, threshold=0.5):
    
    for res in result:
        cat_id, score, bbox = res[0], res[1], res[2:]
        if score < threshold:
    	    continue
        for i in bbox:
            int(i)
        xmin, ymin, xmax, ymax = bbox
        cv2.rectangle(frame, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (255,0,255), 2)
        print('category id is {}, bbox is {}'.format(cat_id, bbox))
        try:
            # #cv2.putText(å›¾åƒ, æ–‡å­—, (x, y), å­—ä½“, å¤§å°, (b, g, r), å®½åº¦)
            cv2.putText(frame, text, (int(xmin), int(ymin-2)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)
            cv2.putText(frame, str(round(score,2)), (int(xmin), int(ymin+8)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)
        except KeyError:
            pass



class Camera:
    def __init__(self, src=0):
        self.src = src
        self.stream = cv2.VideoCapture(src)
        self.stopped = False
        self.thread =  threading.Thread(target=self.update, args=())
        for _ in range(10): #warm up the camera
            (self.grabbed, self.frame) = self.stream.read()
        
    def start(self):
       self.thread.start()

    def update(self):
        while True:
            if self.stopped:
                return
            (self.grabbed, self.frame) = self.stream.read()

    def read(self):
        return self.grabbed, self.frame

    def stop(self):
        self.stopped = True
    
    def release(self):
        self.stream.release()
def Distance(px):
    F=1150
    W=4.0
    return W*F/px

#è®¡ç®—æœºè§†è§‰è¯†åˆ«ä»»åŠ¡,é˜»å¡å¼çš„è¯†åˆ«ä½“ç³»
def task(num,tscore,cap):
    res1=[]
    while num>0:
        ret, frame = cap.read()
        data = preprocess(frame, im_size)
        result = predict(predictor, [im_shape, data, scale_factor])
        if len(result[0]) == 0:
            num-=1
            continue
        res=result[0][0]
        cat_id, score, bbox = res[0], res[1], res[2:]
        if score>=tscore:
            xmin, ymin, xmax, ymax = bbox
            # è®¡ç®—ä¹’ä¹“çƒçš„åƒç´ ç›´å¾„
            pingpong_px = math.sqrt((xmax - xmin) ** 2 + (ymax - ymin) ** 2)
            distance = Distance(pingpong_px)
            draw_bbox_image(frame, result[0], str(int(distance)) + "cm", tscore)
            num=0
            res1=res
        cv2.imshow("frame", frame)
        cv2.waitKey(1)
        num-=1
    return np.array(res1)

# é…ç½®æ¨¡å‹å‚æ•°
model_file = "./model/yolo/model.pdmodel"
params_file = "./model/yolo/model.pdiparams"
# åˆå§‹åŒ–é¢„æµ‹æ¨¡å‹
predictor = predict_config(model_file, params_file)

cap = Camera(0)
cap.start()

# å›¾åƒå°ºå¯¸ç›¸å…³å‚æ•°åˆå§‹åŒ–
ret, img = cap.read()
frame=img
if ret==False:
    while True:
        print("error")
im_size = 608

scale_factor = np.array([im_size * 1. / img.shape[0], im_size * 1. / img.shape[1]]).reshape((1, 2)).astype(np.float32)
im_shape = np.array([im_size, im_size]).reshape((1, 2)).astype(np.float32)

cbot=LOBOROBOT()
#å‰è¿›é˜ˆå€¼
UD_flag=0
while True:
    #é™·å…¥é˜»å¡
    res=task(20,0.3,cap)
    if len(res)==0:
        print("å½“å‰è§†é‡æ²¡æœ‰ä¹’ä¹“çƒï¼Œå°è½¦å¼€å§‹å·¦ç§»")
        cbot.turnLeft(50, 1)
        continue
    cat_id, score, bbox = res[0], res[1], res[2:]
    xmin, ymin, xmax, ymax = bbox
    # è®¡ç®—ä¹’ä¹“çƒçš„åƒç´ ç›´å¾„
    pingpong_px = math.sqrt((xmax - xmin) ** 2 + (ymax - ymin) ** 2)
    distance=Distance(pingpong_px)

    #è®¡ç®—ä¹’ä¹“çƒä¸­å¿ƒåæ ‡
    x0 = (xmin + xmax) / 2
    w0 = frame.shape[1] / 2
    r = w0 - x0
    # å·¦ç§»

    print("è½¨è¿¹æ£€æµ‹æ­£å¸¸ï¼Œç»§ç»­å‰è¿›")
    # ----------------------
    # å½“è·ç¦»åœ¨æŸä¸€ä¸ªèŒƒå›´æ—¶è¿›è¡Œå¾—æ“ä½œ
    if 23 < distance:
        print("å°è½¦å‰è¿›")
        cbot.t_up(30,int((distance-20)/10))
        # ----------------------
        continue
    if distance < 17 :
        print("å°è½¦åé€€")
        # ----------------------
        cbot.t_down(30, int((distance-20)/10))
        continue

    #
    print("ä¸‹çˆª")

print("break")
cap.stop()
cap.release()
cv2.destroyAllWindows()
```

#### è‡³æ­¤ï¼Œä¸€è¾†å¯ä»¥æŠ“å–ä¹’ä¹“çƒçš„å°è½¦å‡ºç‚‰äº†ã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/7afab2c078cb40b79a79925b05c1ee849ecbf6351f3e4e5a808c2c195729f138)


# äº”ã€æ€»ç»“

> ç¬¬ä¸€æ¬¡ä½¿ç”¨Jetson Nanoå¾ˆå¤šä¸œè¥¿ä¸å¤ªç†Ÿæ‚‰ï¼Œå¤šäºäº†ä¸€ä½å¤§ä½¬çš„ä½¿ç”¨æ•™ç¨‹åŒ–è§£äº†æˆ‘çš„å›°æ‰°ã€‚ç”±äºè¯¥é¡¹ç›®è¿˜æ¶‰åŠåˆ°äº†èˆµæœºçš„æ§åˆ¶ï¼Œä½†æ˜¯Jetson Nanoçš„å¼•è„šä¸é€‚åˆæ¥èˆµæœºï¼Œå¿…é¡»é‡‡ç”¨æ‰©å±•æ¿ã€‚
å¦å¤–ï¼ŒJetson Nanoæ—¶ä¸æ—¶å°±æ­»æœºï¼Œå¯¼è‡´é¡¹ç›®å¾ˆå¤šæ—¶é—´éƒ½åœ¨æ’æŸ¥é—®é¢˜ï¼Œè‡³ä»Šè¿˜æ˜¯æ²¡æœ‰è§£å†³ã€‚åé¢è€ƒè™‘ä½¿ç”¨æ›´é«˜çº§çš„æ¿å­è¯•è¯•ï¼Œå¯èƒ½æ˜¯æ¿è½½è¿‡é«˜ï¼ŒJetson Nanoçš„è‡ªæˆ‘ä¿æŠ¤æœºåˆ¶é€ æˆçš„ã€‚

# å…­ã€ä¸ªäººä»‹ç»

> æ¹–åŒ—ç»æµå­¦é™¢ è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ åœ¨è¯»å¤§äºŒ

> å¤§ä¸€å‚åŠ è¿‡è®¡ç®—æœºè®¾è®¡å¤§èµ›æ™ºæ…§å¯¼ç›²èµ›é“è·çœäºŒ

> ç›®å‰æ­£åœ¨æ·±å…¥å­¦ä¹ AIï¼Œä¸Šæ‰‹ä¸åˆ°ä¸€å¹´

## å›¢é˜Ÿæˆå‘˜ä»‹ç»

> å°äº‘ æ¹–åŒ—ç»æµå­¦é™¢ ç”µå­å•†åŠ¡ åœ¨è¯»å¤§ä¸€

> ç²¾é€šPythonï¼Œç»¼åˆèƒ½åŠ›å¼º

> é¡¹ç›®çš„æ ¸å¿ƒå…³é”®ä»£ç ç”±ä»–æä¾›

# ç‰¹åˆ«é¸£è°¢
å‘¨å›½æºå›¢é˜Ÿã€ææˆå®‡å›¢é˜Ÿã€å”è€å¸ˆ
>>>>>>> 3bdb02c (2023-4-1)
